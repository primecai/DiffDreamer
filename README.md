# DiffDreamer: Consistent Single-view Perpetual View Generation with Conditional Diffusion Models
[Project Page](https://primecai.github.io/diffdreamer)

![Teaser image](figures/teaser.jpg)

**DiffDreamer: Consistent Single-view Perpetual View Generation with Conditional Diffusion Models**<br>
[Shengqu Cai](https://primecai.github.io/), [Eric Ryan Chan](https://ericryanchan.github.io/), [Songyou Peng](https://pengsongyou.github.io/), [Mohamad Shahbazi](https://people.ee.ethz.ch/~mshahbazi/), [Anton Obukhov](https://www.obukhov.ai/), [Luc Van Gool](https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html), [Gordon Wetzstein](https://stanford.edu/~gordonwz/)

Abstract: *Perpetual view generation—the task of generating long- range novel views by flying into a given image—has been a novel yet promising task. We introduce DiffDreamer, an unsupervised framework capable of synthesizing novel views depicting a long camera trajectory while training solely on internet-collected images of nature scenes. We demonstrate that image-conditioned diffusion models can effectively per- form long-range scene extrapolation while preserving both local and global consistency significantly better than prior GAN-based methods.*
